{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tp_ima_206_gan_Baccari_Mohamed_Mootez.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bYXhEqG-uC3z"},"source":["# TP Coding a GAN in tensorflow/keras\n","\n","Author : Alasdair Newson\n","\n","alasdair.newson@telecom-paris.fr\n","\n","## Objective:\n","\n","The goal of this TP is to explore GANs applied to the mnist and cifar10 datasets.\n","\n","We will start with the mnist dataset.\n","\n","### Your task:\n","You need to add the missing parts in the code (parts between # --- START CODE HERE and # --- END CODE HERE or # FILL IN CODE)\n","\n","First of all, let's load some packages"]},{"cell_type":"code","metadata":{"id":"meKYIDlUysj6","executionInfo":{"status":"ok","timestamp":1652735851497,"user_tz":-120,"elapsed":2805,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"source":["\n","import matplotlib.pyplot as plt\n","import sys\n","import numpy as np\n","import pickle\n","import copy\n","import os\n","\n","import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Activation, ZeroPadding2D,LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose\n","from tensorflow.keras.models import Sequential, Model, load_model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import backend as K"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GgTDA2KIG4Vm"},"source":["## Loading the data\n","\n","We define a function to load the mnist or cifar10 datasets. Note, we normalise the data between -1 and 1 here (this is often the case for GANs)."]},{"cell_type":"code","metadata":{"id":"7LI1KfTHG4tw","executionInfo":{"status":"ok","timestamp":1652735851498,"user_tz":-120,"elapsed":12,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"source":["def load_data(dataset_name):\n","  # Load the dataset\n","  if(dataset_name == 'mnist'):\n","    (X_train, _), (_, _) = mnist.load_data()\n","  elif(dataset_name == 'cifar'):\n","    from keras.datasets import cifar10\n","    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","  else:\n","    print('Error, unknown database')\n","\n","  # Rescale -1 to 1\n","  X_train = X_train / 127.5 - 1.\n","  #add a channel dimension, if need be (for mnist data)\n","  if(X_train.ndim ==3):\n","    X_train = np.expand_dims(X_train, axis=3)\n","  return X_train\n","\t\t"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vi7BsXCsytEd"},"source":["## Model architecture\n","\n","Now, we define the model architecture.\n","\n","For the first dataset, mnist, we are going to use fully connected layers. Implement the following architecture, for the generator and the discriminator :\n","\n","Generator :\n","- Dense layer, to size 256\n","- Leaky ReLU ($\\alpha=0.2$)\n","- Dense layer, to size 256\n","- Leaky ReLU ($\\alpha=0.2$)\n","- Dense layer, output size 784\n","- Tanh activation\n","- Reshape to size $28 \\times 28 \\times 1$\n","\n","Discriminator :\n","- Flatten\n","- Dense layer, to size 512\n","- Leaky ReLU ($\\alpha=0.2$)\n","- Dense layer, output size 256\n","- Leaky ReLU ($\\alpha=0.2$)\n","- Dense layer, output size 1\n","- Sigmoid activation"]},{"cell_type":"code","metadata":{"id":"in24TH-RESPO","executionInfo":{"status":"ok","timestamp":1652735851498,"user_tz":-120,"elapsed":11,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"source":["def build_generator(z_dim,img_shape,dataset_name):\n","\n","  z_rand = Input(shape=(z_dim,))\n","  # BEGIN FILL IN CODE\n","  x= Dense(256,)(z_rand)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Dense(256,)(x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Dense(784,)(x)\n","  x=tf.keras.activations.tanh(x)\n","  output_img=Reshape((28,28,1))(x)\n","  # END FILL IN CODE\n","  model_generator = Model(z_rand, output_img)\n","  model_generator.summary()\n","\n","  return model_generator\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"wuXe9NVXOSnD","executionInfo":{"status":"ok","timestamp":1652735851499,"user_tz":-120,"elapsed":12,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"source":["\n","def build_discriminator(img_shape,dataset_name):\n","\n","  input_img = Input(shape=img_shape)\n","\t\n","  # BEGIN FILL IN CODE\n","  x=Flatten()(input_img)\n","  x=Dense(512,)(x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Dense(256,)(x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Dense(1,activation='sigmoid')(x)\n","  p_true=x\n"," \n","  # END FILL IN CODE\n","\n","  model_discriminator = Model(input_img, p_true)\n","  model_discriminator.summary()\n","\n","  return model_discriminator\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rdznIctaESt-"},"source":["## Loss function\n","\n","\n","The GAN loss function is the following :\n","\\begin{equation}\n","\t\\min_{G} \\max_{D} \\mathbb{E}_{x \\in p_{data}} \\left[ \\log D(x)\\right] +\n","\t\\mathbb{E}_{z \\in p_{z}}\\left[ \\log \\left( 1 - D(G(z)) \\right)\\right],\n","\\end{equation}\n","where $G$ is the generator, $D$ is the discriminator, $z$ is the latent code, which follows a normal distribution.\n","\n","You should notice that this is extremely similar to the binary cross-entropy function. Therefore, there is an intelligent way to train the discriminator : we give it first a batch of real images, and label them as real, and secondly we give a batch of fake images and label them as fake. Therefore, the discriminator training itself is done in two sequential steps (first true, then fake). If the labels are correctly chosen (further on, during training), you can (and __should__) use the binary cross-entropy function.\n","\n","The generator loss, however, must be specified as :\n","- $mean(\\log(1-G(z)))$\n","\n","You can use the ```k.mean``` function for this purpose.\n","\n","\n","The training is carried out sequentially : first we execute a few training steps on the discriminator, and then one on the generator. Therefore, we use two loops : one to train the discriminator (the internal loop) and one to train the generator (external loop). The GAN training algorithm is as follows :\n","\n","- For $i=0$ to $n-1$\n","  - For $j=0$ to $m-1$\n","    - $x \\leftarrow$ random batch of data\n","    - $z \\leftarrow$ random batch of latent codes\n","    - Train discriminator on real images $x$\n","    - Train discriminator on fake images $G(z)$\n","  - $z \\leftarrow$ random batch of latent codes\n","  - Train generator on fake images $G(z)$\n","\n"]},{"cell_type":"code","metadata":{"id":"SbnxHkOsuDOh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652735855897,"user_tz":-120,"elapsed":4409,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}},"outputId":"bb343800-8b56-4888-f505-a030f9760555"},"source":["\n","optimizer = Adam(0.0002, 0.5)\n","dataset_name = 'mnist'\n","X_train = load_data(dataset_name)\n","\n","# default parameters for mnist \n","img_rows = X_train.shape[1]\n","img_cols = X_train.shape[2]\n","img_channels = X_train.shape[3]\n","img_shape = (img_rows, img_cols, img_channels)\n","z_dim = 10\n","\n","# Build and compile the discriminator\n","discriminator = build_discriminator(img_shape,dataset_name)\n","# set discriminator loss\n","discriminator.compile(loss='BinaryCrossentropy', optimizer=optimizer, metrics=['accuracy']) # FILL IN CODE\n","\n","# Build the generator\n","generator = build_generator(z_dim,img_shape,dataset_name)\n","\n","# Create the stacked model\n","#first, create the random vector z in the latent space\n","z = Input(shape=(z_dim,))\n","#create generated (fake) image\n","gen_img = generator(z)  # FILL IN CODE\n","\n","#indicate that for the stacked model, the weights are not trained (we only train the generator in the stacked model)\n","discriminator.trainable = False\n","\n","# The discriminator takes generated images as input and gives a probability of whether it is a true or false image\n","p_true = discriminator(gen_img)  # FILL IN CODE\n","\n","# The combined model  (stacked generator and discriminator)\n","# In this model, we train the generator only\n","stacked_gen_disc = Model(z, p_true)\n","\n","# generator loss\n","generator_loss = K.mean(K.log(1-p_true))  # FILL IN CODE\n","# create stacked model loss\n","stacked_gen_disc.add_loss(generator_loss)\n","stacked_gen_disc.compile(optimizer=optimizer)\n","\n","\t"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense (Dense)               (None, 512)               401920    \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 533,505\n","Trainable params: 533,505\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 10)]              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 256)               2816      \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 256)               65792     \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 784)               201488    \n","                                                                 \n"," tf.math.tanh (TFOpLambda)   (None, 784)               0         \n","                                                                 \n"," reshape (Reshape)           (None, 28, 28, 1)         0         \n","                                                                 \n","=================================================================\n","Total params: 270,096\n","Trainable params: 270,096\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"9Z0IzHPlLLtb"},"source":["### Sampling function\n","\n","We now create a function to sample several images during training (to follow the convergence of the network)"]},{"cell_type":"code","metadata":{"id":"6oaCO17ZGzWN","executionInfo":{"status":"ok","timestamp":1652735855898,"user_tz":-120,"elapsed":6,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"source":["\n","def sample_images(generator,z_dim, rand_seed=30):\n","  #np.random.seed(rand_seed)\n","  r, c = 5, 5\n","  z_random = np.random.normal(0, 1, (r * c, z_dim))\n","  gen_imgs = generator.predict(z_random)\n","\n","  # Rescale images 0 - 1\n","  gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","  fig, axs = plt.subplots(r, c)\n","  cnt = 0\n","  for i in range(r):\n","    for j in range(c):\n","      #black and white images\n","      if(gen_imgs.shape[3] == 1):\n","        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","      elif(gen_imgs.shape[3] == 3):   #colour images\n","        axs[i,j].imshow(gen_imgs[cnt, :,:])\n","      else:\n","        print('Error, unsupported channel size. Dude, I don''t know what you want me to do.\\\n","            I can''t handle this data. You''ve made me very sad ...')\n","      axs[i,j].axis('off')\n","      cnt += 1\n","  plt.show()"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EfcwQGo7G0zA"},"source":["## Training\n","\n","We are now ready to train the network. Here is the training algorithm again :\n","\n","- For $i=0$ to $n-1$\n","  - For $j=0$ to $m-1$\n","    - $x \\leftarrow$ random batch of data\n","    - $z \\leftarrow$ random batch of latent codes\n","    - Train discriminator on real images $x$\n","    - Train discriminator on fake images $G(z)$\n","  - $z \\leftarrow$ random batch of latent codes\n","  - Train generator on fake images $G(z)$\n","\n","You can use ```np.random.normal``` to create a batch of random latent codes, and ```np.random.randint``` to create a batch of random images.\n","\n","You can then train the discriminator and the generator using the ```train_on_batch``` function.\n","\n","We do not worry here about looping over the whole database : just create a random batch at each iteration."]},{"cell_type":"code","metadata":{"id":"gLk9cmsQLL--","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"13TKNH_H2qaF3KMKcE9FRMxekxQe8c4Os"},"executionInfo":{"status":"ok","timestamp":1652736455616,"user_tz":-120,"elapsed":599452,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}},"outputId":"c47816ce-5982-4424-9514-aaa226e3e3a7"},"source":["# parameters for training\n","batch_size=64\n","n_iters_outer=10000\n","sample_interval=100\n","n_iters_inner=1\t#number of internal loops\n","\n","#load dataset\n","X_train = load_data(dataset_name)\n","\n","# Adversarial ground truths\n","d_output_true = np.ones((batch_size,1))  #FILL IN CODE\n","d_output_false = np.zeros((batch_size,1)) #FILL IN CODE\n","\n","# start training \n","for iter_outer in range(0,n_iters_outer):\n","\n","  # ---------------------\n","  #  Train Discriminator\n","  # ---------------------\n","\n","  # Train the discriminator\n","  for iter_inner in range(0,n_iters_inner):\n","    # Select a random batch of images\n","    idx = np.random.randint(0, X_train.shape[0], batch_size)\n","    imgs = X_train[idx]\n","\n","    z_random = np.random.normal(0, 1, (batch_size, z_dim))\n","\n","    # Generate a batch of new (fake) images\n","    gen_imgs = generator.predict(z_random)\n","    #print(gen_imgs)\n","    d_loss_real = discriminator.train_on_batch(imgs, d_output_true)  # FILL IN CODE\n","    d_loss_fake = discriminator.train_on_batch(gen_imgs, d_output_false) # FILL IN CODE\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","  \n","  # ---------------------\n","  #  Train Generator\n","  # ---------------------\n","\n","\n","  z_random = np.random.normal(0, 1, (batch_size, z_dim))\n","\n","  # Generator training : try to make generated images be classified as true by the discriminator\n","  g_loss = stacked_gen_disc.train_on_batch(z_random)\n","\n","  # Save some random generated images and the models at every sample_interval iterations\n","  if (iter_outer % sample_interval == 0):\n","    print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iter_outer, d_loss[0], 100*d_loss[1], g_loss))\n","    sample_images(generator,z_dim, rand_seed=30)"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Interpolation in the latent space \n","\n","Very often, we wish to not only generate samples, but also _interpolate_ between two codes in the latent space (for example, interpolating between a boot and a shoe, as seen in the lesson).\n","\n","In this part, we will carry out this interpolation, and see what sort of intermediate results are produced.\n","\n","First of all, draw two samples in the latent space such that the generated images are realistic enough (you can try different ones changing the seed of the random number generator)."],"metadata":{"id":"43c9xB5OcDta"}},{"cell_type":"code","source":["# FILL IN CODE\n","z_random = np.random.normal(0, 1, (2, z_dim))\n","gen_imgs = generator.predict(z_random)\n","gen_imgs=0.5*gen_imgs+0.5 #rescaling\n","fig,axs = plt.subplots(1,2)\n","axs[0].imshow(gen_imgs[0, :,:,0], cmap='gray')\n","axs[1].imshow(gen_imgs[1, :,:,0], cmap='gray')"],"metadata":{"id":"3DHjNAdycFCA","colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"status":"ok","timestamp":1652736455948,"user_tz":-120,"elapsed":339,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}},"outputId":"60fa1900-6b2f-4075-afed-4c4e932648bd"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f08de0b1990>"]},"metadata":{},"execution_count":8},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Now, interpolate between the two codes, using 10 steps, and show the intermediate results."],"metadata":{"id":"smMretSHcJfS"}},{"cell_type":"code","source":["# FILL IN CODE\n","p1=z_random[0]\n","p2=z_random[1]\n","s= np.linspace(0,1,num=10)\n","v=[]\n","for p in s :\n","  vect= (1-p)*p1+p*p2\n","  v.append(vect)\n","print(v)\n","gen_imgs=generator.predict(np.array(v))\n","print(gen_imgs.shape)\n","gen_imgs=0.5*gen_imgs+0.5 #rescaling"],"metadata":{"id":"J7uVj-Y3cN4h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652736455949,"user_tz":-120,"elapsed":18,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}},"outputId":"1e15b78d-68df-467b-a3c5-a87ba897f3e2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[array([ 0.41514214,  0.55381169, -0.26616234,  2.19680258,  0.0438125 ,\n","       -1.58723185,  1.09714524,  1.20216848,  2.11769791, -1.31995997]), array([ 0.34107505,  0.64990337, -0.18216636,  2.14713743,  0.20089685,\n","       -1.34876094,  1.02187542,  1.07646538,  2.08044187, -1.01245131]), array([ 0.26700797,  0.74599504, -0.09817039,  2.09747228,  0.3579812 ,\n","       -1.11029003,  0.94660561,  0.95076229,  2.04318584, -0.70494265]), array([ 0.19294089,  0.84208672, -0.01417442,  2.04780713,  0.51506555,\n","       -0.87181912,  0.87133579,  0.82505919,  2.0059298 , -0.39743399]), array([ 0.1188738 ,  0.93817839,  0.06982156,  1.99814198,  0.67214989,\n","       -0.63334821,  0.79606597,  0.6993561 ,  1.96867376, -0.08992533]), array([ 0.04480672,  1.03427007,  0.15381753,  1.94847683,  0.82923424,\n","       -0.39487729,  0.72079616,  0.573653  ,  1.93141773,  0.21758332]), array([-0.02926037,  1.13036175,  0.2378135 ,  1.89881168,  0.98631859,\n","       -0.15640638,  0.64552634,  0.44794991,  1.89416169,  0.52509198]), array([-0.10332745,  1.22645342,  0.32180948,  1.84914652,  1.14340294,\n","        0.08206453,  0.57025653,  0.32224682,  1.85690565,  0.83260064]), array([-0.17739454,  1.3225451 ,  0.40580545,  1.79948137,  1.30048729,\n","        0.32053544,  0.49498671,  0.19654372,  1.81964962,  1.1401093 ]), array([-0.25146162,  1.41863677,  0.48980142,  1.74981622,  1.45757164,\n","        0.55900635,  0.4197169 ,  0.07084063,  1.78239358,  1.44761796])]\n","(10, 28, 28, 1)\n"]}]},{"cell_type":"code","source":["fig,axs= plt.subplots(2,5)\n","axs[0,0].imshow(gen_imgs[0, :,:,0], cmap='gray')\n","axs[0,1].imshow(gen_imgs[1, :,:,0], cmap='gray')\n","axs[0,2].imshow(gen_imgs[2, :,:,0], cmap='gray')\n","axs[0,3].imshow(gen_imgs[3, :,:,0], cmap='gray')\n","axs[0,4].imshow(gen_imgs[4, :,:,0], cmap='gray')\n","axs[1,0].imshow(gen_imgs[5, :,:,0], cmap='gray')\n","axs[1,1].imshow(gen_imgs[6, :,:,0], cmap='gray')\n","axs[1,2].imshow(gen_imgs[7, :,:,0], cmap='gray')\n","axs[1,3].imshow(gen_imgs[8, :,:,0], cmap='gray')\n","axs[1,4].imshow(gen_imgs[9, :,:,0], cmap='gray')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"hJ6d1A01kynv","executionInfo":{"status":"ok","timestamp":1652736456776,"user_tz":-120,"elapsed":833,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}},"outputId":"b60956bd-1959-4f51-e37d-323ebccbcf3e"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 10 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["__Question__ Do the intermediate results always look like valid numbers ? If this is not the case, then what explanation do you have for this ?"],"metadata":{"id":"pp5PrGVEcOor"}},{"cell_type":"markdown","source":["* No this is not the case, the generators needs some iterations to become able to generate fake images that the discriminator can't detect."],"metadata":{"id":"EwxECLwLn7MX"}},{"cell_type":"markdown","source":["__Answer__"],"metadata":{"id":"_XK9L6_acT-j"}},{"cell_type":"markdown","metadata":{"id":"eKRGvUZaVWK3"},"source":["# Training on CIFAR\n","\n","Use the above code and modify it to carry out the GAN training on the CIFAR10 database.\n","\n","For this case, implement the following architecture :\n","\n","- Generator :\n","  - Dense layer to size 1024\n","  - BatchNormalization, momentum=0.8\n","  - Leaky ReLU ($\\alpha=0.2$)\n","  - Reshape, to size $4 \\times 4 \\times64$\n","  - % size = $4\\times4\\times64$\n","  - Conv2DTranspose, filters=16,kernel size=(5,5), strides=(2,2),padding=same\n","  - %size = $8\\times 8\\times 16$\n","  - BatchNormalization, momentum=0.8\n","  - Leaky ReLU ($\\alpha=0.2$)\n","  - Conv2DTranspose, filters=16,kernel size=(4,4), strides=(2,2),padding=same\n","  - %size=$16 \\times 16 \\times 16$\n","  - BatchNormalization, momentum=0.8\n","  - Leaky ReLU ($\\alpha=0.2$)\n","  - Conv2DTranspose, filters=32,kernel size=(5,5), strides=(2,2),padding=same\n","  - %size = $32 \\times 32 \\times 32$\n","  - BatchNormalization, momentum=0.8\n","  - Leaky ReLU ($\\alpha=0.2$)\n","  - Conv2D, filters=3,kernel size=(5,5), strides=(1,1),padding=same\n","  - %size = $32 \\times 32 \\times 3$\n","  - Tanh activation ( you can use ```Activation('tanh')```)\n","\n","- Discriminator :\n","  - % input size : $32 \\times 32 \\times 3$\n","  - Conv2D, 32 filters, kernel size = (3,3), strides = (1,1),padding = same\n","  - % size $32 \\times 32 \\times 32$\n","  - Leaky ReLU ($\\alpha=0.2$)\n","  - Conv2D, 32 filters, kernel size = (3,3), strides = (2,2),padding = same\n","  - %size : $16 \\times 16 \\times 32$\n","  - Leaky ReLU ($\\alpha=0.2$)\n","  - Conv2D, 64 filters, kernel size = (3,3), strides = (2,2),padding = same\n","  - % size : $8 \\times 8 \\times 64$\n","  - Leaky ReLU ($\\alpha=0.2$)\n","  - Conv2D, 32 filters, kernel size = (3,3), strides = (2,2),padding = same\n","  - % size : $4 \\times 4 \\times 32$\n","  - Leaky ReLU ($\\alpha=0.2$)\n","  - Flatten\n","  - Dense layer, to size 1\n","  - Sigmoid activation\n","\n","  Implement this architecture below, and train the GAN. __Do not worry too much about the quality of the output images__, to get good results, longer training is usually required."]},{"cell_type":"code","metadata":{"id":"97W-qqT0GtaE","executionInfo":{"status":"ok","timestamp":1652736456777,"user_tz":-120,"elapsed":9,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"source":["def build_generator(z_dim,img_shape,dataset_name):\n","\n","  z_rand = Input(shape=(z_dim,))\n","  # BEGIN FILL IN CODE\n","  x=Dense( 1024,) (z_rand)\n","  x=BatchNormalization(momentum=0.8) (x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Reshape((4,4,64) ) (x)\n","  x=Conv2DTranspose(16,kernel_size=5,padding='same',strides=(2,2))(x)\n","  x=BatchNormalization(momentum=0.8) (x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Conv2DTranspose(16,kernel_size=4,padding='same',strides=(2,2)) (x)\n","  x=BatchNormalization(momentum=0.8) (x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Conv2DTranspose (32,kernel_size=5,padding='same',strides=(2,2)) (x)\n","  x=BatchNormalization(momentum=0.8) (x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Conv2D (3,kernel_size=5,padding='same',strides=(1,1)) (x)\n","  output_img = tf.keras.activations.tanh(x)\n","  # END FILL IN CODE\n","  model_generator = Model(z_rand, output_img)\n","  model_generator.summary()\n","\n","  return model_generator\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","def build_discriminator(img_shape,dataset_name):\n","\n","  input_img = Input(shape=img_shape)\n","\t\n","  # BEGIN FILL IN CODE\n","  \n","  x=Conv2D(32,kernel_size=3,padding='same',strides=(1,1)) (input_img)\n","  x=BatchNormalization(momentum=0.8) (x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","\n","  x=Conv2D(32,kernel_size=3,padding='same',strides=(2,2)) (x)\n","  x=BatchNormalization(momentum=0.8) (x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","\n","  x=Conv2D(64,kernel_size=3,padding='same',strides=(2,2)) (x)\n","  x=BatchNormalization(momentum=0.8) (x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","\n","  x=Conv2D(32,kernel_size=3,padding='same',strides=(2,2))(x)\n","  x=BatchNormalization(momentum=0.8) (x)\n","  x=LeakyReLU(alpha=0.2)(x)\n","  x=Flatten()(x)\n","  p_true=Dense(1,activation='sigmoid') (x)\n","\n","  \n","\n","  # END FILL IN CODE\n","\n","  model_discriminator=Model(input_img, p_true)\n","  model_discriminator.summary()\n","\n","  return model_discriminator\n"],"metadata":{"id":"lAKW5dKHUUmw","executionInfo":{"status":"ok","timestamp":1652736456777,"user_tz":-120,"elapsed":8,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\n","def sample_images(generator,z_dim, rand_seed=30):\n","  #np.random.seed(rand_seed)\n","  r, c = 5, 5\n","  z_random = np.random.normal(0, 1, (r * c, z_dim))\n","  gen_imgs = generator.predict(z_random)\n","\n","  # Rescale images 0 - 1\n","  gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","  fig, axs = plt.subplots(r, c)\n","  cnt = 0\n","  for i in range(r):\n","    for j in range(c):\n","      #black and white images\n","      if(gen_imgs.shape[3] == 1):\n","        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","      elif(gen_imgs.shape[3] == 3):   #colour images\n","        axs[i,j].imshow(gen_imgs[cnt, :,:])\n","      else:\n","        print('Error, unsupported channel size. Dude, I don''t know what you want me to do.\\\n","            I can''t handle this data. You''ve made me very sad ...')\n","      axs[i,j].axis('off')\n","      cnt += 1\n","  plt.show()"],"metadata":{"id":"NbGx_EmYUa7n","executionInfo":{"status":"ok","timestamp":1652736456778,"user_tz":-120,"elapsed":9,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["\n","optimizer = Adam(0.0002, 0.5)\n","dataset_name = 'cifar'\n","X_train = load_data(dataset_name)\n","\n","# default parameters for cifar \n","img_rows = X_train.shape[1]\n","img_cols = X_train.shape[2]\n","img_channels = X_train.shape[3]\n","img_shape = (img_rows, img_cols, img_channels)\n","z_dim = 10\n","\n","# Build and compile the discriminator\n","discriminator = build_discriminator(img_shape,dataset_name)\n","# set discriminator loss\n","discriminator.compile(loss='BinaryCrossentropy', optimizer=optimizer, metrics=['accuracy']) # FILL IN CODE\n","\n","# Build the generator\n","generator = build_generator(z_dim,img_shape,dataset_name)\n","\n","# Create the stacked model\n","#first, create the random vector z in the latent space\n","z = Input(shape=(z_dim,))\n","#create generated (fake) image\n","gen_img = generator(z)  # FILL IN CODE\n","\n","#indicate that for the stacked model, the weights are not trained (we only train the generator in the stacked model)\n","discriminator.trainable = False\n","\n","# The discriminator takes generated images as input and gives a probability of whether it is a true or false image\n","p_true = discriminator(gen_img)  # FILL IN CODE\n","\n","# The combined model  (stacked generator and discriminator)\n","# In this model, we train the generator only\n","stacked_gen_disc = Model(z, p_true)\n","\n","# generator loss\n","generator_loss = K.mean(K.log(1-p_true))  # FILL IN CODE\n","# create stacked model loss\n","stacked_gen_disc.add_loss(generator_loss)\n","stacked_gen_disc.compile(optimizer=optimizer)\n","\n","\t"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsEPpte8Uj9T","executionInfo":{"status":"ok","timestamp":1652736462732,"user_tz":-120,"elapsed":5962,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}},"outputId":"ab804107-d375-4a12-cd01-7ac0afc9d821"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n","Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 32, 32, 32)        896       \n","                                                                 \n"," batch_normalization (BatchN  (None, 32, 32, 32)       128       \n"," ormalization)                                                   \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 32)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 16, 16, 32)        9248      \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 32)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 8, 8, 64)          18496     \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 8, 8, 64)         256       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_6 (LeakyReLU)   (None, 8, 8, 64)          0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 4, 4, 32)          18464     \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 4, 4, 32)         128       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 4, 4, 32)          0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 512)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 48,257\n","Trainable params: 47,937\n","Non-trainable params: 320\n","_________________________________________________________________\n","Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 10)]              0         \n","                                                                 \n"," dense_7 (Dense)             (None, 1024)              11264     \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 1024)             4096      \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_8 (LeakyReLU)   (None, 1024)              0         \n","                                                                 \n"," reshape_1 (Reshape)         (None, 4, 4, 64)          0         \n","                                                                 \n"," conv2d_transpose (Conv2DTra  (None, 8, 8, 16)         25616     \n"," nspose)                                                         \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 8, 8, 16)         64        \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_9 (LeakyReLU)   (None, 8, 8, 16)          0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2DT  (None, 16, 16, 16)       4112      \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 16, 16, 16)       64        \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_10 (LeakyReLU)  (None, 16, 16, 16)        0         \n","                                                                 \n"," conv2d_transpose_2 (Conv2DT  (None, 32, 32, 32)       12832     \n"," ranspose)                                                       \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," leaky_re_lu_11 (LeakyReLU)  (None, 32, 32, 32)        0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 32, 32, 3)         2403      \n","                                                                 \n"," tf.math.tanh_1 (TFOpLambda)  (None, 32, 32, 3)        0         \n","                                                                 \n","=================================================================\n","Total params: 60,579\n","Trainable params: 58,403\n","Non-trainable params: 2,176\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# parameters for training\n","batch_size=64\n","n_iters_outer=10000\n","sample_interval=100\n","n_iters_inner=1\t#number of internal loops\n","\n","#load dataset\n","X_train = load_data(dataset_name)\n","\n","# Adversarial ground truths\n","d_output_true = np.ones((batch_size,1))  #FILL IN CODE\n","d_output_false = np.zeros((batch_size,1)) #FILL IN CODE\n","\n","# start training \n","for iter_outer in range(0,n_iters_outer):\n","\n","  # ---------------------\n","  #  Train Discriminator\n","  # ---------------------\n","\n","  # Train the discriminator\n","  for iter_inner in range(0,n_iters_inner):\n","    # Select a random batch of images\n","    idx = np.random.randint(0, X_train.shape[0], batch_size)\n","    imgs = X_train[idx]\n","\n","    z_random = np.random.normal(0, 1, (batch_size, z_dim))\n","\n","    # Generate a batch of new (fake) images\n","    gen_imgs = generator.predict(z_random)\n","    #print(gen_imgs)\n","    d_loss_real = discriminator.train_on_batch(imgs, d_output_true)  # FILL IN CODE\n","    d_loss_fake = discriminator.train_on_batch(gen_imgs, d_output_false) # FILL IN CODE\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","  \n","  # ---------------------\n","  #  Train Generator\n","  # ---------------------\n","\n","\n","  z_random = np.random.normal(0, 1, (batch_size, z_dim))\n","\n","  # Generator training : try to make generated images be classified as true by the discriminator\n","  g_loss = stacked_gen_disc.train_on_batch(z_random)\n","\n","  # Save some random generated images and the models at every sample_interval iterations\n","  if (iter_outer % sample_interval == 0):\n","    print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iter_outer, d_loss[0], 100*d_loss[1], g_loss))\n","    sample_images(generator,z_dim, rand_seed=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hx3Qb00FWYHTsM3POcvh7K1gpJOy4YJ1"},"id":"F00gn5JaUwr6","outputId":"7c39fd08-a8ba-48bb-98eb-cb7d24de3f04","executionInfo":{"status":"ok","timestamp":1652737357050,"user_tz":-120,"elapsed":894332,"user":{"displayName":"Mootez Baccari","userId":"18220885954194655250"}}},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}